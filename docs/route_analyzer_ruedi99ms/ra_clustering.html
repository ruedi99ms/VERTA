<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>route_analyzer_ruedi99ms.ra_clustering API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>route_analyzer_ruedi99ms.ra_clustering</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># ------------------------------
# Clustering
# ------------------------------

from typing import Tuple
import numpy as np
import pandas as pd

def kmeans_2d(vectors: np.ndarray, k: int = 3, max_iter: int = 100, seed: int = 0) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Tiny k-means for 2D vectors. Returns (labels, centers).&#34;&#34;&#34;
    if len(vectors) &lt; k:
        raise ValueError(&#34;Not enough vectors for requested k&#34;)
    rng = np.random.default_rng(seed)
    centers = vectors[rng.choice(len(vectors), size=k, replace=False)].copy()
    labels = np.zeros(len(vectors), dtype=int)
    for _ in range(max_iter):
        # assign
        d = np.linalg.norm(vectors[:, None, :] - centers[None, :, :], axis=2)
        labels = np.argmin(d, axis=1)
        # update
        new_centers = centers.copy()
        for j in range(k):
            pts = vectors[labels == j]
            if len(pts) &gt; 0:
                new_centers[j] = pts.mean(axis=0)
        if np.allclose(new_centers, centers):
            break
        centers = new_centers
    return labels, centers

def best_k_by_silhouette(V: np.ndarray, k_min=2, k_max=6, seed=42):
    scores = {}
    for k in range(k_min, k_max + 1):
        if V.shape[0] &lt;= k:
            continue
        labels, centers = kmeans_2d(V, k=k, seed=seed)
        S = _cosine_silhouette_score(V, labels)
        scores[k] = S
    if not scores:
        return min(3, max(1, V.shape[0])), {}
    best_k = max(scores, key=scores.get)
    return best_k, scores

def _cosine_silhouette_score(V: np.ndarray, labels: np.ndarray) -&gt; float:
    &#34;&#34;&#34;
    Silhouette score using cosine distance 1 - dot(u,v) for unit vectors.
    Works without sklearn. Returns mean silhouette over all points with a valid cluster.
    &#34;&#34;&#34;
    if V.size == 0 or labels.size != V.shape[0]:
        return 0.0
    # Precompute dot-similarity matrix (cosine on unit vectors = dot)
    D = V @ V.T  # in [-1,1]; similarity
    # Convert to distance
    dist = 1.0 - D
    n = len(V)
    s_vals = []
    for i in range(n):
        Li = labels[i]
        if Li &lt; 0:  # noise/outlier: skip
            continue
        same = (labels == Li)
        other = (labels != Li) &amp; (labels &gt;= 0)

        # a(i): mean intra-cluster distance (excluding self)
        si = dist[i, same]
        if si.size &lt;= 1:
            a = 0.0
        else:
            a = float((si.sum() - 0.0) / max(1, si.size - 1))

        # b(i): min mean distance to other clusters
        b = None
        for Lj in set(labels[other]):
            mask = (labels == Lj)
            if not mask.any():
                continue
            b_j = float(dist[i, mask].mean())
            b = b_j if b is None else min(b, b_j)
        if b is None:
            # no other clusters; silhouette undefined → 0
            s = 0.0
        else:
            s = 0.0 if (a == b == 0.0) else (b - a) / max(a, b)
        s_vals.append(s)
    return float(np.mean(s_vals)) if s_vals else 0.0

def merge_close_centers(centers: np.ndarray, labels: np.ndarray, min_sep_deg=12.0):
    if centers.shape[0] &lt;= 1: 
        return centers, labels
    ang = np.arctan2(centers[:,1], centers[:,0])
    keep = np.ones(len(centers), dtype=bool)
    map_to = np.arange(len(centers))
    for i in range(len(centers)):
        if not keep[i]: 
            continue
        for j in range(i+1, len(centers)):
            if not keep[j]: 
                continue
            d = np.abs((ang[i]-ang[j]+np.pi)%(2*np.pi)-np.pi)
            if np.degrees(d) &lt; min_sep_deg:
                # merge j -&gt; i
                keep[j] = False
                map_to[map_to == j] = i
    new_ids = {old: idx for idx, old in enumerate(np.where(keep)[0])}
    new_centers = centers[keep]
    new_labels  = np.array([ new_ids[ map_to[l] ] for l in labels ], dtype=int)
    return new_centers, new_labels

def split_small_branches(assign_df: pd.DataFrame, min_frac=0.05):
    # assign_df: columns [&#34;trajectory&#34;,&#34;branch&#34;]
    counts = assign_df[&#34;branch&#34;].value_counts().sort_index()
    n = int(counts.sum())
    small = set(counts[counts &lt; max(1, int(np.ceil(min_frac*n)))].index)
    main  = assign_df[~assign_df[&#34;branch&#34;].isin(small)].copy()
    minor = assign_df[ assign_df[&#34;branch&#34;].isin(small)].copy()
    
    print(f&#34;[debug] split_small_branches: original branches={sorted(assign_df[&#39;branch&#39;].unique())}&#34;)
    print(f&#34;[debug] split_small_branches: small branches={sorted(small)}&#34;)
    print(f&#34;[debug] split_small_branches: main branches before renumbering={sorted(main[&#39;branch&#39;].unique())}&#34;)
    
    # Renumber main branches to start from 0
    if len(main) &gt; 0:
        unique_branches = sorted(main[&#34;branch&#34;].unique())
        branch_mapping = {old: new for new, old in enumerate(unique_branches)}
        main[&#34;branch&#34;] = main[&#34;branch&#34;].map(branch_mapping)
        print(f&#34;[debug] split_small_branches: branch_mapping={branch_mapping}&#34;)
        print(f&#34;[debug] split_small_branches: main branches after renumbering={sorted(main[&#39;branch&#39;].unique())}&#34;)
    
    return main, minor, counts

def cluster_angles_dbscan(V: np.ndarray, eps_deg=15.0, min_samples=5):
    &#34;&#34;&#34;
    Simple DBSCAN on the unit circle without sklearn.
    - Build neighbor graph by chord distance threshold derived from eps_deg.
    - Core points have &gt;= min_samples neighbors (incl. self).
    - Expand clusters via BFS; others labeled -1.
    Returns (labels, centers[unit vectors]).
    &#34;&#34;&#34;
    if V.size == 0:
        return np.zeros((0,), dtype=int), np.zeros((0, 2), dtype=float)

    # Convert to angle embedding on unit circle (already unit vectors)
    X = V  # (n,2), assumed ~unit
    # chord distance threshold for angular eps:
    # chord = 2*sin(eps/2)
    eps = 2.0 * np.sin(np.deg2rad(eps_deg) / 2.0)

    # pairwise chord distances on unit circle between X[i], X[j]: ||X[i]-X[j]||
    # use (a-b)^2 = a^2 + b^2 - 2 a·b; here a^2=b^2=1 =&gt; ||a-b||^2 = 2 - 2(a·b)
    S = X @ X.T  # dot
    sq_chord = 2.0 - 2.0 * S
    sq_eps = eps * eps
    neigh = (sq_chord &lt;= sq_eps)

    n = len(X)
    labels = np.full(n, -1, dtype=int)
    visited = np.zeros(n, dtype=bool)
    core = np.sum(neigh, axis=1) &gt;= min_samples

    cid = 0
    for i in range(n):
        if visited[i]:
            continue
        visited[i] = True
        if not core[i]:
            continue
        # start new cluster
        labels[i] = cid
        # expand via BFS over density-reachable points
        queue = [i]
        while queue:
            p = queue.pop()
            Np = np.where(neigh[p])[0]
            for q in Np:
                if not visited[q]:
                    visited[q] = True
                    if core[q]:
                        queue.append(q)
                if labels[q] == -1:
                    labels[q] = cid
        cid += 1

    # compute centers as normalized mean of unit vectors per cluster
    centers = []
    for c in range(cid):
        idx = (labels == c)
        m = X[idx].mean(axis=0)
        nrm = np.linalg.norm(m)
        centers.append(m / nrm if nrm &gt; 0 else np.array([1.0, 0.0]))
    centers = np.array(centers) if centers else np.zeros((0, 2))
    return labels, centers</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="route_analyzer_ruedi99ms.ra_clustering.best_k_by_silhouette"><code class="name flex">
<span>def <span class="ident">best_k_by_silhouette</span></span>(<span>V: numpy.ndarray, k_min=2, k_max=6, seed=42)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_k_by_silhouette(V: np.ndarray, k_min=2, k_max=6, seed=42):
    scores = {}
    for k in range(k_min, k_max + 1):
        if V.shape[0] &lt;= k:
            continue
        labels, centers = kmeans_2d(V, k=k, seed=seed)
        S = _cosine_silhouette_score(V, labels)
        scores[k] = S
    if not scores:
        return min(3, max(1, V.shape[0])), {}
    best_k = max(scores, key=scores.get)
    return best_k, scores</code></pre>
</details>
</dd>
<dt id="route_analyzer_ruedi99ms.ra_clustering.cluster_angles_dbscan"><code class="name flex">
<span>def <span class="ident">cluster_angles_dbscan</span></span>(<span>V: numpy.ndarray, eps_deg=15.0, min_samples=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Simple DBSCAN on the unit circle without sklearn.
- Build neighbor graph by chord distance threshold derived from eps_deg.
- Core points have &gt;= min_samples neighbors (incl. self).
- Expand clusters via BFS; others labeled -1.
Returns (labels, centers[unit vectors]).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cluster_angles_dbscan(V: np.ndarray, eps_deg=15.0, min_samples=5):
    &#34;&#34;&#34;
    Simple DBSCAN on the unit circle without sklearn.
    - Build neighbor graph by chord distance threshold derived from eps_deg.
    - Core points have &gt;= min_samples neighbors (incl. self).
    - Expand clusters via BFS; others labeled -1.
    Returns (labels, centers[unit vectors]).
    &#34;&#34;&#34;
    if V.size == 0:
        return np.zeros((0,), dtype=int), np.zeros((0, 2), dtype=float)

    # Convert to angle embedding on unit circle (already unit vectors)
    X = V  # (n,2), assumed ~unit
    # chord distance threshold for angular eps:
    # chord = 2*sin(eps/2)
    eps = 2.0 * np.sin(np.deg2rad(eps_deg) / 2.0)

    # pairwise chord distances on unit circle between X[i], X[j]: ||X[i]-X[j]||
    # use (a-b)^2 = a^2 + b^2 - 2 a·b; here a^2=b^2=1 =&gt; ||a-b||^2 = 2 - 2(a·b)
    S = X @ X.T  # dot
    sq_chord = 2.0 - 2.0 * S
    sq_eps = eps * eps
    neigh = (sq_chord &lt;= sq_eps)

    n = len(X)
    labels = np.full(n, -1, dtype=int)
    visited = np.zeros(n, dtype=bool)
    core = np.sum(neigh, axis=1) &gt;= min_samples

    cid = 0
    for i in range(n):
        if visited[i]:
            continue
        visited[i] = True
        if not core[i]:
            continue
        # start new cluster
        labels[i] = cid
        # expand via BFS over density-reachable points
        queue = [i]
        while queue:
            p = queue.pop()
            Np = np.where(neigh[p])[0]
            for q in Np:
                if not visited[q]:
                    visited[q] = True
                    if core[q]:
                        queue.append(q)
                if labels[q] == -1:
                    labels[q] = cid
        cid += 1

    # compute centers as normalized mean of unit vectors per cluster
    centers = []
    for c in range(cid):
        idx = (labels == c)
        m = X[idx].mean(axis=0)
        nrm = np.linalg.norm(m)
        centers.append(m / nrm if nrm &gt; 0 else np.array([1.0, 0.0]))
    centers = np.array(centers) if centers else np.zeros((0, 2))
    return labels, centers</code></pre>
</details>
</dd>
<dt id="route_analyzer_ruedi99ms.ra_clustering.kmeans_2d"><code class="name flex">
<span>def <span class="ident">kmeans_2d</span></span>(<span>vectors: numpy.ndarray, k: int = 3, max_iter: int = 100, seed: int = 0) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Tiny k-means for 2D vectors. Returns (labels, centers).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kmeans_2d(vectors: np.ndarray, k: int = 3, max_iter: int = 100, seed: int = 0) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Tiny k-means for 2D vectors. Returns (labels, centers).&#34;&#34;&#34;
    if len(vectors) &lt; k:
        raise ValueError(&#34;Not enough vectors for requested k&#34;)
    rng = np.random.default_rng(seed)
    centers = vectors[rng.choice(len(vectors), size=k, replace=False)].copy()
    labels = np.zeros(len(vectors), dtype=int)
    for _ in range(max_iter):
        # assign
        d = np.linalg.norm(vectors[:, None, :] - centers[None, :, :], axis=2)
        labels = np.argmin(d, axis=1)
        # update
        new_centers = centers.copy()
        for j in range(k):
            pts = vectors[labels == j]
            if len(pts) &gt; 0:
                new_centers[j] = pts.mean(axis=0)
        if np.allclose(new_centers, centers):
            break
        centers = new_centers
    return labels, centers</code></pre>
</details>
</dd>
<dt id="route_analyzer_ruedi99ms.ra_clustering.merge_close_centers"><code class="name flex">
<span>def <span class="ident">merge_close_centers</span></span>(<span>centers: numpy.ndarray, labels: numpy.ndarray, min_sep_deg=12.0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_close_centers(centers: np.ndarray, labels: np.ndarray, min_sep_deg=12.0):
    if centers.shape[0] &lt;= 1: 
        return centers, labels
    ang = np.arctan2(centers[:,1], centers[:,0])
    keep = np.ones(len(centers), dtype=bool)
    map_to = np.arange(len(centers))
    for i in range(len(centers)):
        if not keep[i]: 
            continue
        for j in range(i+1, len(centers)):
            if not keep[j]: 
                continue
            d = np.abs((ang[i]-ang[j]+np.pi)%(2*np.pi)-np.pi)
            if np.degrees(d) &lt; min_sep_deg:
                # merge j -&gt; i
                keep[j] = False
                map_to[map_to == j] = i
    new_ids = {old: idx for idx, old in enumerate(np.where(keep)[0])}
    new_centers = centers[keep]
    new_labels  = np.array([ new_ids[ map_to[l] ] for l in labels ], dtype=int)
    return new_centers, new_labels</code></pre>
</details>
</dd>
<dt id="route_analyzer_ruedi99ms.ra_clustering.split_small_branches"><code class="name flex">
<span>def <span class="ident">split_small_branches</span></span>(<span>assign_df: pandas.core.frame.DataFrame, min_frac=0.05)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_small_branches(assign_df: pd.DataFrame, min_frac=0.05):
    # assign_df: columns [&#34;trajectory&#34;,&#34;branch&#34;]
    counts = assign_df[&#34;branch&#34;].value_counts().sort_index()
    n = int(counts.sum())
    small = set(counts[counts &lt; max(1, int(np.ceil(min_frac*n)))].index)
    main  = assign_df[~assign_df[&#34;branch&#34;].isin(small)].copy()
    minor = assign_df[ assign_df[&#34;branch&#34;].isin(small)].copy()
    
    print(f&#34;[debug] split_small_branches: original branches={sorted(assign_df[&#39;branch&#39;].unique())}&#34;)
    print(f&#34;[debug] split_small_branches: small branches={sorted(small)}&#34;)
    print(f&#34;[debug] split_small_branches: main branches before renumbering={sorted(main[&#39;branch&#39;].unique())}&#34;)
    
    # Renumber main branches to start from 0
    if len(main) &gt; 0:
        unique_branches = sorted(main[&#34;branch&#34;].unique())
        branch_mapping = {old: new for new, old in enumerate(unique_branches)}
        main[&#34;branch&#34;] = main[&#34;branch&#34;].map(branch_mapping)
        print(f&#34;[debug] split_small_branches: branch_mapping={branch_mapping}&#34;)
        print(f&#34;[debug] split_small_branches: main branches after renumbering={sorted(main[&#39;branch&#39;].unique())}&#34;)
    
    return main, minor, counts</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="route_analyzer_ruedi99ms" href="index.html">route_analyzer_ruedi99ms</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="route_analyzer_ruedi99ms.ra_clustering.best_k_by_silhouette" href="#route_analyzer_ruedi99ms.ra_clustering.best_k_by_silhouette">best_k_by_silhouette</a></code></li>
<li><code><a title="route_analyzer_ruedi99ms.ra_clustering.cluster_angles_dbscan" href="#route_analyzer_ruedi99ms.ra_clustering.cluster_angles_dbscan">cluster_angles_dbscan</a></code></li>
<li><code><a title="route_analyzer_ruedi99ms.ra_clustering.kmeans_2d" href="#route_analyzer_ruedi99ms.ra_clustering.kmeans_2d">kmeans_2d</a></code></li>
<li><code><a title="route_analyzer_ruedi99ms.ra_clustering.merge_close_centers" href="#route_analyzer_ruedi99ms.ra_clustering.merge_close_centers">merge_close_centers</a></code></li>
<li><code><a title="route_analyzer_ruedi99ms.ra_clustering.split_small_branches" href="#route_analyzer_ruedi99ms.ra_clustering.split_small_branches">split_small_branches</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>