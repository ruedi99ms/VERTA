<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>verta.verta_commands API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>verta.verta_commands</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="verta.verta_commands.AssignCommand"><code class="flex name class">
<span>class <span class="ident">AssignCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AssignCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for branch assignment using precomputed centers&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)
        parser.add_argument(&#34;--junction&#34;, nargs=2, type=float, required=True, metavar=(&#34;X&#34;, &#34;Z&#34;), help=&#34;Junction coordinates&#34;)
        parser.add_argument(&#34;--radius&#34;, type=float, required=True, help=&#34;Junction radius&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;pathlen&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--r_outer&#34;, type=float, default=None, help=&#34;Outer radius for radial mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--centers&#34;, required=True, help=&#34;Path to precomputed centers&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        self._create_output_dir(args.out)

        with self.logger.operation(&#34;Loading trajectories&#34;):
            trajectories = load_folder(
                args.input, args.glob,
                columns=args.columns,
                require_time=False,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )

        if len(trajectories) == 0:
            self.logger.error(&#34;No trajectories loaded. Check your input path, file pattern, and column mappings.&#34;)
            return

        junction = Circle(cx=float(args.junction[0]), cz=float(args.junction[1]), r=float(args.radius))
        centers = np.load(args.centers)

        with self.logger.operation(&#34;Assigning branches&#34;):
            assignments = assign_branches(
                trajectories, centers, junction,
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                decision_mode=args.decision_mode,
                r_outer=float(args.r_outer) if args.r_outer is not None else None,
                linger_delta=float(args.linger_delta),
                out_dir=args.out
            )
        # Normalize/validate and add branch_j0 for single-junction compatibility
        try:
            validate_trajectories_unique(trajectories)
        except Exception:
            pass
        if &#34;branch_j0&#34; not in assignments.columns:
            assignments = assignments.copy()
            assignments[&#34;branch_j0&#34;] = assignments[&#34;branch&#34;]

        # Consistency warnings (after enriching columns)
        try:
            from .verta_consistency import validate_consistency
            validate_consistency(assignments, trajectories, [junction])
        except Exception:
            pass

        save_assignments(assignments, os.path.join(args.out, &#34;branch_assignments.csv&#34;))
        self._save_run_args(args, args.out)
        self.logger.info(f&#34;Assignment completed. Results saved to {args.out}&#34;)</code></pre>
</details>
<div class="desc"><p>Command handler for branch assignment using precomputed centers</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
<li><code><a title="verta.verta_commands.BaseCommand.execute" href="#verta.verta_commands.BaseCommand.execute">execute</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.BaseCommand"><code class="flex name class">
<span>class <span class="ident">BaseCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseCommand(ABC):
    &#34;&#34;&#34;Abstract base class for all commands&#34;&#34;&#34;

    def __init__(self):
        self.logger = VERTALogger()

    @abstractmethod
    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        &#34;&#34;&#34;Add command-specific arguments&#34;&#34;&#34;
        pass

    @abstractmethod
    def execute(self, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Execute the command&#34;&#34;&#34;
        pass

    def _create_output_dir(self, out_path: str) -&gt; None:
        &#34;&#34;&#34;Create output directory if it doesn&#39;t exist&#34;&#34;&#34;
        os.makedirs(out_path, exist_ok=True)

    def _save_run_args(self, args: argparse.Namespace, out_path: str) -&gt; None:
        &#34;&#34;&#34;Save run arguments to JSON file&#34;&#34;&#34;
        args_path = os.path.join(out_path, &#34;run_args.json&#34;)
        with open(args_path, &#34;w&#34;) as f:
            json.dump(vars(args), f, indent=2)</code></pre>
</details>
<div class="desc"><p>Abstract base class for all commands</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.AssignCommand" href="#verta.verta_commands.AssignCommand">AssignCommand</a></li>
<li><a title="verta.verta_commands.DiscoverCommand" href="#verta.verta_commands.DiscoverCommand">DiscoverCommand</a></li>
<li><a title="verta.verta_commands.EnhancedChainCommand" href="#verta.verta_commands.EnhancedChainCommand">EnhancedChainCommand</a></li>
<li><a title="verta.verta_commands.GUICommand" href="#verta.verta_commands.GUICommand">GUICommand</a></li>
<li><a title="verta.verta_commands.GazeCommand" href="#verta.verta_commands.GazeCommand">GazeCommand</a></li>
<li><a title="verta.verta_commands.IntentRecognitionCommand" href="#verta.verta_commands.IntentRecognitionCommand">IntentRecognitionCommand</a></li>
<li><a title="verta.verta_commands.MetricsCommand" href="#verta.verta_commands.MetricsCommand">MetricsCommand</a></li>
<li><a title="verta.verta_commands.PredictCommand" href="#verta.verta_commands.PredictCommand">PredictCommand</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="verta.verta_commands.BaseCommand.add_arguments"><code class="name flex">
<span>def <span class="ident">add_arguments</span></span>(<span>self, parser: argparse.ArgumentParser) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
    &#34;&#34;&#34;Add command-specific arguments&#34;&#34;&#34;
    pass</code></pre>
</details>
<div class="desc"><p>Add command-specific arguments</p></div>
</dd>
<dt id="verta.verta_commands.BaseCommand.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, args: argparse.Namespace) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def execute(self, args: argparse.Namespace) -&gt; None:
    &#34;&#34;&#34;Execute the command&#34;&#34;&#34;
    pass</code></pre>
</details>
<div class="desc"><p>Execute the command</p></div>
</dd>
</dl>
</dd>
<dt id="verta.verta_commands.CommandConfig"><code class="flex name class">
<span>class <span class="ident">CommandConfig</span></span>
<span>(</span><span>input: str,<br>glob: str = '*.csv',<br>columns: Dict[str, str] | None = None,<br>scale: float = 1.0,<br>motion_threshold: float = 0.001,<br>out: str | None = None,<br>config: str | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class CommandConfig:
    &#34;&#34;&#34;Shared configuration for all commands&#34;&#34;&#34;
    input: str
    glob: str = &#34;*.csv&#34;
    columns: Optional[Dict[str, str]] = None
    scale: float = 1.0
    motion_threshold: float = 0.001
    out: Optional[str] = None
    config: Optional[str] = None # Added for consistency, though handled by main</code></pre>
</details>
<div class="desc"><p>Shared configuration for all commands</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="verta.verta_commands.CommandConfig.columns"><code class="name">var <span class="ident">columns</span> : Dict[str, str] | None</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.config"><code class="name">var <span class="ident">config</span> : str | None</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.glob"><code class="name">var <span class="ident">glob</span> : str</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.input"><code class="name">var <span class="ident">input</span> : str</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.motion_threshold"><code class="name">var <span class="ident">motion_threshold</span> : float</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.out"><code class="name">var <span class="ident">out</span> : str | None</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
<dt id="verta.verta_commands.CommandConfig.scale"><code class="name">var <span class="ident">scale</span> : float</code></dt>
<dd>
<div class="desc"><p>The type of the None singleton.</p></div>
</dd>
</dl>
</dd>
<dt id="verta.verta_commands.DiscoverCommand"><code class="flex name class">
<span>class <span class="ident">DiscoverCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DiscoverCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for branch discovery&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)
        parser.add_argument(&#34;--junction&#34;, nargs=2, type=float, required=True, metavar=(&#34;X&#34;, &#34;Z&#34;), help=&#34;Junction coordinates&#34;)
        parser.add_argument(&#34;--radius&#34;, type=float, required=True, help=&#34;Junction radius&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--k&#34;, type=int, default=3, help=&#34;Number of clusters&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;hybrid&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--r_outer&#34;, type=float, default=None, help=&#34;Outer radius for radial mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--cluster_method&#34;, choices=[&#34;kmeans&#34;, &#34;auto&#34;, &#34;dbscan&#34;], default=&#34;kmeans&#34;, help=&#34;Clustering method&#34;)
        parser.add_argument(&#34;--k_min&#34;, type=int, default=2, help=&#34;Minimum k for auto clustering&#34;)
        parser.add_argument(&#34;--k_max&#34;, type=int, default=6, help=&#34;Maximum k for auto clustering&#34;)
        parser.add_argument(&#34;--min_sep_deg&#34;, type=float, default=12.0, help=&#34;Minimum separation in degrees&#34;)
        parser.add_argument(&#34;--angle_eps&#34;, type=float, default=15.0, help=&#34;Angle epsilon for DBSCAN&#34;)
        parser.add_argument(&#34;--min_samples&#34;, type=int, default=5, help=&#34;Minimum samples for DBSCAN&#34;)
        parser.add_argument(&#34;--seed&#34;, type=int, default=0, help=&#34;Random seed&#34;)
        parser.add_argument(&#34;--plot_intercepts&#34;, action=&#34;store_true&#34;, default=True, help=&#34;Plot decision intercepts&#34;)
        parser.add_argument(&#34;--show_paths&#34;, action=&#34;store_true&#34;, default=True, help=&#34;Show trajectory paths&#34;)
        parser.add_argument(&#34;--outlier_frac&#34;, type=float, default=0.05, help=&#34;Outlier fraction threshold&#34;)
        parser.add_argument(&#34;--outlier_min&#34;, type=int, default=3, help=&#34;Minimum outlier count&#34;)
        parser.add_argument(&#34;--plot_outliers&#34;, action=&#34;store_true&#34;, help=&#34;Plot outlier trajectories&#34;)
        parser.add_argument(&#34;--plot_noenter_paths&#34;, action=&#34;store_true&#34;, help=&#34;Plot no-entry paths&#34;)
        parser.add_argument(&#34;--legend_noenter_as_line&#34;, action=&#34;store_true&#34;, help=&#34;Legend style for no-entry&#34;)
        parser.add_argument(&#34;--include_noenter_in_assignments&#34;, action=&#34;store_true&#34;, help=&#34;Include no-entry in assignments&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        self._create_output_dir(args.out)

        with self.logger.operation(&#34;Loading trajectories&#34;):
            trajectories = load_folder(
                args.input, args.glob,
                columns=args.columns,
                require_time=False,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )

        if len(trajectories) == 0:
            self.logger.error(&#34;No trajectories loaded. Check your input path, file pattern, and column mappings.&#34;)
            return

        junction = Circle(cx=float(args.junction[0]), cz=float(args.junction[1]), r=float(args.radius))

        with self.logger.operation(&#34;Discovering branches&#34;):
            assignments, summary, centers = discover_branches(
                trajectories, junction,
                k=int(args.k),
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                seed=int(args.seed),
                decision_mode=args.decision_mode,
                r_outer=float(args.r_outer) if args.r_outer is not None else None,
                linger_delta=float(args.linger_delta),
                out_dir=args.out,
                cluster_method=args.cluster_method,
                k_min=int(args.k_min),
                k_max=int(args.k_max),
                min_sep_deg=float(args.min_sep_deg),
                angle_eps=float(args.angle_eps),
                min_samples=int(args.min_samples),
                junction_number=0,  # CLI discover command is always for junction 0
                all_junctions=[junction]
            )

        with self.logger.operation(&#34;Processing assignments&#34;):
            self._process_assignments(assignments, centers, args)

        with self.logger.operation(&#34;Generating plots&#34;):
            self._generate_plots(trajectories, assignments, centers, junction, args)

        self._save_run_args(args, args.out)
        self.logger.info(f&#34;Discovery completed. Results saved to {args.out}&#34;)

    def _process_assignments(self, assignments: pd.DataFrame, centers: np.ndarray, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Process and save assignment results&#34;&#34;&#34;
        # Save all assignments
        save_assignments(assignments, os.path.join(args.out, &#34;branch_assignments_main.csv&#34;))

        # Create summary
        summary_all = (assignments[&#34;branch&#34;]
                    .value_counts()
                    .sort_index()
                    .rename_axis(&#34;branch&#34;)
                    .to_frame(&#34;count&#34;))
        summary_all[&#34;percent&#34;] = summary_all[&#34;count&#34;] / max(1, int(summary_all[&#34;count&#34;].sum())) * 100.0
        save_summary(summary_all.reset_index(), os.path.join(args.out, &#34;branch_summary_all.csv&#34;), with_entropy=True)

        # Split small branches
        min_needed = max(int(np.ceil(float(args.outlier_frac) * len(assignments))), int(args.outlier_min))
        main_assign, minor_assign, counts = split_small_branches(assignments, min_frac=float(args.outlier_frac))

        if len(minor_assign):
            small_branches_abs = set(counts[counts &lt; min_needed].index)
            if small_branches_abs:
                keep_mask = ~main_assign[&#34;branch&#34;].isin(small_branches_abs)
                extra_minor = main_assign[~keep_mask]
                main_assign = main_assign[keep_mask]
                minor_assign = pd.concat([minor_assign, extra_minor], ignore_index=True)

        # Save main assignments
        save_assignments(main_assign, os.path.join(args.out, &#34;branch_assignments.csv&#34;))

        # Include no-entry if requested
        if args.include_noenter_in_assignments:
            all_path = os.path.join(args.out, &#34;branch_assignments_all.csv&#34;)
            if os.path.exists(all_path):
                df_all = pd.read_csv(all_path)
                noenter = df_all[df_all[&#34;branch&#34;] == -2]
                combined = pd.concat([main_assign, noenter], ignore_index=True)
                save_assignments(combined, os.path.join(args.out, &#34;branch_assignments.csv&#34;))

        # Create main summary
        summary_main = (main_assign[&#34;branch&#34;]
                        .value_counts()
                        .sort_index()
                        .rename_axis(&#34;branch&#34;)
                        .to_frame(&#34;count&#34;))
        summary_main[&#34;percent&#34;] = summary_main[&#34;count&#34;] / max(1, int(summary_main[&#34;count&#34;].sum())) * 100.0
        save_summary(summary_main.reset_index(), os.path.join(args.out, &#34;branch_summary.csv&#34;), with_entropy=True)

        # Log outlier info
        if len(minor_assign):
            self.logger.info(f&#34;Flagged outlier branches: {len(minor_assign)} trajectories &#34;
                            f&#34;(threshold = max({args.outlier_frac*100:.1f}% of N, {args.outlier_min}))&#34;)
        else:
            self.logger.info(&#34;No outlier branches flagged&#34;)

        # Save centers
        save_centers(centers, os.path.join(args.out, &#34;branch_centers.npy&#34;))
        save_centers_json(centers, os.path.join(args.out, &#34;branch_centers.json&#34;))

    def _generate_plots(self, trajectories, assignments, centers, junction, args):
        &#34;&#34;&#34;Generate visualization plots&#34;&#34;&#34;
        main_assignments = pd.read_csv(os.path.join(args.out, &#34;branch_assignments.csv&#34;))

        # Branch directions plot (optional - function may not exist)
        try:
            from .verta_plotting import plot_branch_directions
            plot_branch_directions(centers, (junction.cx, junction.cz),
                                 os.path.join(args.out, &#34;Branch_Directions.png&#34;))
        except (ImportError, AttributeError):
            self.logger.warning(&#34;plot_branch_directions not available, skipping&#34;)

        # Branch counts plot (optional - function may not exist)
        try:
            from .verta_plotting import plot_branch_counts
            plot_branch_counts(main_assignments, os.path.join(args.out, &#34;Branch_Counts.png&#34;))
        except (ImportError, AttributeError):
            self.logger.warning(&#34;plot_branch_counts not available, skipping&#34;)

        # Decision intercepts plot
        if args.plot_intercepts:
            try:
                assign_all_path = os.path.join(args.out, &#34;branch_assignments_all.csv&#34;)
                if args.plot_outliers and os.path.exists(assign_all_path):
                    assign_for_plot = pd.read_csv(assign_all_path)
                else:
                    assign_for_plot = main_assignments

                mode_log_path = os.path.join(args.out, &#34;decision_mode_used.csv&#34;)
                mode_log_df = pd.read_csv(mode_log_path) if os.path.exists(mode_log_path) else None

                # Load decision points data for plotting
                decision_points_df = None
                try:
                    decision_points_path = os.path.join(args.out, &#34;decision_points.csv&#34;)
                    if os.path.exists(decision_points_path):
                        decision_points_df = pd.read_csv(decision_points_path)
                except Exception:
                    pass

                plot_decision_intercepts(
                    trajectories=trajectories,
                    assignments_df=assign_for_plot,
                    mode_log_df=mode_log_df,
                    centers=centers,
                    junction=junction,
                    r_outer=float(args.r_outer) if args.r_outer is not None else None,
                    path_length=float(args.distance),
                    epsilon=float(args.epsilon),
                    linger_delta=float(args.linger_delta),
                    out_path=os.path.join(args.out, &#34;Decision_Intercepts.png&#34;),
                    show_paths=False,
                    legend_noenter_as_line=args.legend_noenter_as_line,
                    decision_points_df=decision_points_df
                )
                self.logger.info(&#34;Decision intercepts plot generated&#34;)
            except Exception as e:
                self.logger.error(f&#34;Intercept plot failed: {e}&#34;)

        # Decision map plot (optional - function may not exist)
        try:
            from .verta_plotting import plot_discover_map
            plot_discover_map(
                trajectories=trajectories,
                assignments_df=main_assignments,
                junction=junction,
                centers=centers,
                r_outer=float(args.r_outer) if args.r_outer is not None else None,
                out_path=os.path.join(args.out, &#34;Decision_Map.png&#34;)
            )
            self.logger.info(&#34;Decision map plot generated&#34;)
        except (ImportError, AttributeError, NameError) as e:
            self.logger.warning(f&#34;plot_discover_map not available, skipping: {e}&#34;)</code></pre>
</details>
<div class="desc"><p>Command handler for branch discovery</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
<li><code><a title="verta.verta_commands.BaseCommand.execute" href="#verta.verta_commands.BaseCommand.execute">execute</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.EnhancedChainCommand"><code class="flex name class">
<span>class <span class="ident">EnhancedChainCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EnhancedChainCommand(BaseCommand):
    &#34;&#34;&#34;Enhanced command handler for multi-junction decision chain analysis with flow graph features&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)
        parser.add_argument(&#34;--junctions&#34;, nargs=&#34;+&#34;, type=float, required=True, help=&#34;Junction coordinates (x z r ...)&#34;)
        parser.add_argument(&#34;--r_outer_list&#34;, nargs=&#34;*&#34;, type=float, default=None, help=&#34;Outer radii for each junction&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--k&#34;, type=int, default=3, help=&#34;Number of clusters&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;hybrid&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--cluster_method&#34;, choices=[&#34;kmeans&#34;, &#34;auto&#34;, &#34;dbscan&#34;], default=&#34;kmeans&#34;, help=&#34;Clustering method&#34;)
        parser.add_argument(&#34;--k_min&#34;, type=int, default=2, help=&#34;Minimum k for auto clustering&#34;)
        parser.add_argument(&#34;--k_max&#34;, type=int, default=6, help=&#34;Maximum k for auto clustering&#34;)
        parser.add_argument(&#34;--min_sep_deg&#34;, type=float, default=12.0, help=&#34;Minimum separation in degrees&#34;)
        parser.add_argument(&#34;--angle_eps&#34;, type=float, default=15.0, help=&#34;Angle epsilon for DBSCAN&#34;)
        parser.add_argument(&#34;--min_samples&#34;, type=int, default=5, help=&#34;Minimum samples for DBSCAN&#34;)
        parser.add_argument(&#34;--seed&#34;, type=int, default=0, help=&#34;Random seed&#34;)
        parser.add_argument(&#34;--small_multiples&#34;, action=&#34;store_true&#34;, help=&#34;Generate small multiples plot&#34;)
        parser.add_argument(&#34;--small_multiples_window&#34;, type=float, default=80.0, help=&#34;Small multiples window size&#34;)

        # Enhanced analysis flags
        parser.add_argument(&#34;--evacuation_analysis&#34;, action=&#34;store_true&#34;, help=&#34;Run enhanced flow analysis&#34;)
        parser.add_argument(&#34;--generate_recommendations&#34;, action=&#34;store_true&#34;, help=&#34;Generate flow recommendations&#34;)
        parser.add_argument(&#34;--risk_assessment&#34;, action=&#34;store_true&#34;, help=&#34;Generate risk assessment&#34;)
        parser.add_argument(&#34;--efficiency_metrics&#34;, action=&#34;store_true&#34;, help=&#34;Generate efficiency metrics&#34;)

        # Junction naming
        parser.add_argument(&#34;--junction_names&#34;, nargs=&#34;*&#34;, type=str, default=None, help=&#34;Names for junctions&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Execute enhanced chain analysis&#34;&#34;&#34;
        self.logger.info(&#34;Starting Loading trajectories&#34;)

        # Load trajectories
        trajectories = load_folder(
            folder=args.input,
            pattern=args.glob,
            columns=args.columns,
            scale=args.scale,
            motion_threshold=args.motion_threshold
        )

        if len(trajectories) == 0:
            self.logger.warning(&#34;No trajectories loaded. Exiting.&#34;)
            return

        self.logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

        # Parse junctions
        junctions = self._parse_junctions(args.junctions)

        # Parse r_outer_list
        rlist = args.r_outer_list or [None] * len(junctions)

        self.logger.info(&#34;Starting Discovering decision chain&#34;)

        # Discover decision chain
        chain_df, centers_list = discover_decision_chain(
            trajectories=trajectories,
            junctions=junctions,
            r_outer_list=rlist,
            path_length=args.distance,
            epsilon=args.epsilon,
            k=args.k,
            decision_mode=args.decision_mode,
            linger_delta=args.linger_delta,
            cluster_method=args.cluster_method,
            k_min=args.k_min,
            k_max=args.k_max,
            min_sep_deg=args.min_sep_deg,
            angle_eps=args.angle_eps,
            min_samples=args.min_samples,
            seed=args.seed,
            out_dir=args.out
        )

        self.logger.info(&#34;Completed Discovering decision chain&#34;)

        # Generate chain plots
        self.logger.info(&#34;Starting Generating chain plots&#34;)
        self._generate_chain_plots(trajectories, chain_df, junctions, rlist, args)
        self.logger.info(&#34;Completed Generating chain plots&#34;)

        # Run enhanced analysis if requested
        if args.evacuation_analysis:
            self.logger.info(&#34;Starting Running enhanced flow analysis&#34;)
            self._run_enhanced_analysis(chain_df, junctions, trajectories, args)
            self.logger.info(&#34;Completed Running enhanced flow analysis&#34;)

        self.logger.info(&#34;Enhanced chain analysis completed. Results saved to &#34; + args.out)

    def _parse_junctions(self, junction_coords: list) -&gt; list:
        &#34;&#34;&#34;Parse junction coordinates into Circle objects&#34;&#34;&#34;
        if len(junction_coords) % 3 != 0:
            raise ValueError(&#34;Junction coordinates must be triples: x z r ...&#34;)

        junctions = []
        for i in range(0, len(junction_coords), 3):
            x, z, r = junction_coords[i:i+3]
            junctions.append(Circle(cx=x, cz=z, r=r))

        return junctions

    def _generate_chain_plots(self, trajectories, chain_df, junctions, rlist, args):
        &#34;&#34;&#34;Generate chain visualization plots&#34;&#34;&#34;
        try:
            plot_chain_overview(
                trajectories=trajectories,
                chain_df=chain_df,
                junctions=junctions,
                r_outer_list=rlist,
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                linger_delta=float(args.linger_delta),
                decision_mode=str(args.decision_mode),
                out_path=os.path.join(args.out, &#34;Chain_Overview.png&#34;),
                show_paths=True,
                show_centers=False,
                centers_list=None,
                annotate_counts=False,
            )
            self.logger.info(&#34;Chain overview plot generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Chain overview plot failed: {e}&#34;)

        # Always generate small multiples for enhanced chain analysis
        try:
            plot_chain_small_multiples(
                trajectories=trajectories,
                chain_df=chain_df,
                junctions=junctions,
                r_outer_list=rlist,
                window_radius=float(args.small_multiples_window),
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                linger_delta=float(args.linger_delta),
                decision_mode=str(args.decision_mode),
                out_path=os.path.join(args.out, &#34;Chain_SmallMultiples.png&#34;),
            )
            self.logger.info(&#34;Chain small multiples plot generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Chain small multiples plot failed: {e}&#34;)

        # Generate flow graph map
        try:
            plot_flow_graph_map(
                trajectories=trajectories,
                chain_df=chain_df,
                junctions=junctions,
                r_outer_list=rlist,
                out_path=os.path.join(args.out, &#34;Flow_Graph_Map.png&#34;),
                junction_names=getattr(args, &#39;junction_names&#39;, None),
                show_junction_names=True,
                min_flow_threshold=0.01,  # Show flows &gt;= 1%
                arrow_scale=1.0,
                start_zones=getattr(args, &#39;start_zones&#39;, None),
                end_zones=getattr(args, &#39;end_zones&#39;, None),
            )
            self.logger.info(&#34;Flow graph map generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Flow graph map failed: {e}&#34;)

    def _run_enhanced_analysis(self, chain_df, junctions, trajectories, args):
        &#34;&#34;&#34;Run enhanced flow analysis - simplified to only generate flow maps&#34;&#34;&#34;
        try:
            # Generate per-junction flow graph map
            plot_per_junction_flow_graph(
                trajectories=trajectories,
                chain_df=chain_df,
                junctions=junctions,
                r_outer_list=getattr(args, &#39;r_outer_list&#39;, None),
                out_path=os.path.join(args.out, &#34;Per_Junction_Flow_Graph.png&#34;),
                junction_names=getattr(args, &#39;junction_names&#39;, None),
                show_junction_names=True,
                min_flow_threshold=0.01,  # Show flows &gt;= 1%
                arrow_scale=1.0,
                start_zones=getattr(args, &#39;start_zones&#39;, None),
                end_zones=getattr(args, &#39;end_zones&#39;, None),
            )
            self.logger.info(&#34;Per-junction flow graph map generated&#34;)

        except Exception as e:
            self.logger.error(f&#34;Enhanced analysis failed: {e}&#34;)
            import traceback
            traceback.print_exc()</code></pre>
</details>
<div class="desc"><p>Enhanced command handler for multi-junction decision chain analysis with flow graph features</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="verta.verta_commands.EnhancedChainCommand.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, args: argparse.Namespace) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, args: argparse.Namespace) -&gt; None:
    &#34;&#34;&#34;Execute enhanced chain analysis&#34;&#34;&#34;
    self.logger.info(&#34;Starting Loading trajectories&#34;)

    # Load trajectories
    trajectories = load_folder(
        folder=args.input,
        pattern=args.glob,
        columns=args.columns,
        scale=args.scale,
        motion_threshold=args.motion_threshold
    )

    if len(trajectories) == 0:
        self.logger.warning(&#34;No trajectories loaded. Exiting.&#34;)
        return

    self.logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

    # Parse junctions
    junctions = self._parse_junctions(args.junctions)

    # Parse r_outer_list
    rlist = args.r_outer_list or [None] * len(junctions)

    self.logger.info(&#34;Starting Discovering decision chain&#34;)

    # Discover decision chain
    chain_df, centers_list = discover_decision_chain(
        trajectories=trajectories,
        junctions=junctions,
        r_outer_list=rlist,
        path_length=args.distance,
        epsilon=args.epsilon,
        k=args.k,
        decision_mode=args.decision_mode,
        linger_delta=args.linger_delta,
        cluster_method=args.cluster_method,
        k_min=args.k_min,
        k_max=args.k_max,
        min_sep_deg=args.min_sep_deg,
        angle_eps=args.angle_eps,
        min_samples=args.min_samples,
        seed=args.seed,
        out_dir=args.out
    )

    self.logger.info(&#34;Completed Discovering decision chain&#34;)

    # Generate chain plots
    self.logger.info(&#34;Starting Generating chain plots&#34;)
    self._generate_chain_plots(trajectories, chain_df, junctions, rlist, args)
    self.logger.info(&#34;Completed Generating chain plots&#34;)

    # Run enhanced analysis if requested
    if args.evacuation_analysis:
        self.logger.info(&#34;Starting Running enhanced flow analysis&#34;)
        self._run_enhanced_analysis(chain_df, junctions, trajectories, args)
        self.logger.info(&#34;Completed Running enhanced flow analysis&#34;)

    self.logger.info(&#34;Enhanced chain analysis completed. Results saved to &#34; + args.out)</code></pre>
</details>
<div class="desc"><p>Execute enhanced chain analysis</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.GUICommand"><code class="flex name class">
<span>class <span class="ident">GUICommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GUICommand(BaseCommand):
    &#34;&#34;&#34;Command handler for launching the web GUI&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--port&#34;, type=int, default=8501, help=&#34;Port to run the GUI on (default: 8501)&#34;)
        parser.add_argument(&#34;--host&#34;, type=str, default=&#34;localhost&#34;, help=&#34;Host to run the GUI on (default: localhost)&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Launch the Streamlit GUI&#34;&#34;&#34;
        try:
            import streamlit
        except ImportError:
            self.logger.error(&#34;Streamlit is not installed. Install GUI dependencies with: pip install verta[gui]&#34;)
            return

        import subprocess
        import sys
        from pathlib import Path

        # Get the path to verta_gui.py
        gui_path = Path(__file__).parent / &#34;verta_gui.py&#34;
        
        if not gui_path.exists():
            self.logger.error(f&#34;GUI file not found at: {gui_path}&#34;)
            return

        # Build streamlit command
        cmd = [
            sys.executable, &#34;-m&#34;, &#34;streamlit&#34;, &#34;run&#34;,
            str(gui_path),
            &#34;--server.port&#34;, str(args.port),
            &#34;--server.address&#34;, args.host
        ]

        self.logger.info(f&#34;Launching VERTA GUI on http://{args.host}:{args.port}&#34;)
        self.logger.info(&#34;Press Ctrl+C to stop the server&#34;)

        try:
            subprocess.run(cmd)
        except KeyboardInterrupt:
            self.logger.info(&#34;GUI stopped by user&#34;)
        except Exception as e:
            self.logger.error(f&#34;Failed to launch GUI: {e}&#34;)
            raise</code></pre>
</details>
<div class="desc"><p>Command handler for launching the web GUI</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="verta.verta_commands.GUICommand.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, args: argparse.Namespace) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, args: argparse.Namespace) -&gt; None:
    &#34;&#34;&#34;Launch the Streamlit GUI&#34;&#34;&#34;
    try:
        import streamlit
    except ImportError:
        self.logger.error(&#34;Streamlit is not installed. Install GUI dependencies with: pip install verta[gui]&#34;)
        return

    import subprocess
    import sys
    from pathlib import Path

    # Get the path to verta_gui.py
    gui_path = Path(__file__).parent / &#34;verta_gui.py&#34;
    
    if not gui_path.exists():
        self.logger.error(f&#34;GUI file not found at: {gui_path}&#34;)
        return

    # Build streamlit command
    cmd = [
        sys.executable, &#34;-m&#34;, &#34;streamlit&#34;, &#34;run&#34;,
        str(gui_path),
        &#34;--server.port&#34;, str(args.port),
        &#34;--server.address&#34;, args.host
    ]

    self.logger.info(f&#34;Launching VERTA GUI on http://{args.host}:{args.port}&#34;)
    self.logger.info(&#34;Press Ctrl+C to stop the server&#34;)

    try:
        subprocess.run(cmd)
    except KeyboardInterrupt:
        self.logger.info(&#34;GUI stopped by user&#34;)
    except Exception as e:
        self.logger.error(f&#34;Failed to launch GUI: {e}&#34;)
        raise</code></pre>
</details>
<div class="desc"><p>Launch the Streamlit GUI</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.GazeCommand"><code class="flex name class">
<span>class <span class="ident">GazeCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GazeCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for gaze and physiological analysis&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)

        junction_group = parser.add_mutually_exclusive_group(required=True)
        junction_group.add_argument(&#34;--junction&#34;, nargs=2, type=float, metavar=(&#34;X&#34;, &#34;Z&#34;), help=&#34;Single junction coordinates&#34;)
        junction_group.add_argument(&#34;--junctions&#34;, nargs=&#34;+&#34;, type=float, help=&#34;Multiple junction coordinates (x z r ...)&#34;)

        parser.add_argument(&#34;--radius&#34;, type=float, default=None, help=&#34;Junction radius&#34;)
        parser.add_argument(&#34;--r_outer&#34;, type=float, default=None, help=&#34;Outer radius for radial mode&#34;)
        parser.add_argument(&#34;--r_outer_list&#34;, nargs=&#34;*&#34;, type=float, default=None, help=&#34;Outer radii for each junction&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;hybrid&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--cluster_method&#34;, choices=[&#34;kmeans&#34;, &#34;auto&#34;, &#34;dbscan&#34;], default=&#34;kmeans&#34;, help=&#34;Clustering method&#34;)
        parser.add_argument(&#34;--k&#34;, type=int, default=3, help=&#34;Number of clusters&#34;)
        parser.add_argument(&#34;--k_min&#34;, type=int, default=2, help=&#34;Minimum k for auto clustering&#34;)
        parser.add_argument(&#34;--k_max&#34;, type=int, default=6, help=&#34;Maximum k for auto clustering&#34;)
        parser.add_argument(&#34;--min_sep_deg&#34;, type=float, default=12.0, help=&#34;Minimum separation in degrees&#34;)
        parser.add_argument(&#34;--angle_eps&#34;, type=float, default=15.0, help=&#34;Angle epsilon for DBSCAN&#34;)
        parser.add_argument(&#34;--min_samples&#34;, type=int, default=5, help=&#34;Minimum samples for DBSCAN&#34;)
        parser.add_argument(&#34;--seed&#34;, type=int, default=0, help=&#34;Random seed&#34;)
        parser.add_argument(&#34;--centers&#34;, help=&#34;Path to pre-computed branch centers (.npy file)&#34;)
        parser.add_argument(&#34;--physio_window&#34;, type=float, default=3.0, help=&#34;Physiological analysis window&#34;)
        parser.add_argument(&#34;--plot_outliers&#34;, action=&#34;store_true&#34;, help=&#34;Include outlier branches in gaze plots (gray)&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        self._create_output_dir(args.out)

        with self.logger.operation(&#34;Loading gaze trajectories&#34;):
            gaze_trajectories = load_folder_with_gaze(
                args.input, args.glob,
                columns=args.columns,
                require_time=True,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )

        if len(gaze_trajectories) == 0:
            self.logger.error(&#34;No gaze trajectories loaded. Check your input path, file pattern, and column mappings.&#34;)
            return

        # Parse junctions
        if hasattr(args, &#39;junction&#39;) and args.junction is not None:
            junctions = [Circle(cx=float(args.junction[0]), cz=float(args.junction[1]), r=float(args.radius))]
            rlist = [float(args.r_outer)] if args.r_outer is not None else None
        else:
            vals = list(map(float, args.junctions))
            if len(vals) % 3 != 0:
                raise ValueError(&#34;--junctions must be triples: x z r ...&#34;)
            triples = [vals[i:i+3] for i in range(0, len(vals), 3)]
            junctions = [Circle(cx=a, cz=b, r=c) for a, b, c in triples]
            rlist = list(args.r_outer_list) if args.r_outer_list is not None and len(args.r_outer_list) &gt; 0 else None

        with self.logger.operation(&#34;Discovering branches for gaze analysis&#34;):
            chain_df, centers_list = discover_decision_chain(
                trajectories=gaze_trajectories,
                junctions=junctions,
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                seed=int(args.seed),
                decision_mode=str(args.decision_mode),
                r_outer_list=rlist,
                linger_delta=float(args.linger_delta),
                out_dir=str(args.out),
                cluster_method=str(args.cluster_method),
                k=int(args.k),
                k_min=int(args.k_min),
                k_max=int(args.k_max),
                min_sep_deg=float(args.min_sep_deg),
                angle_eps=float(args.angle_eps),
                min_samples=int(args.min_samples),
            )

        with self.logger.operation(&#34;Computing gaze analysis&#34;):
            # Normalize assignments and merge decisions when available
            decisions_path = os.path.join(str(args.out), &#34;branch_decisions_chain.csv&#34;)
            decisions_df = pd.read_csv(decisions_path) if os.path.exists(decisions_path) else None
            norm_df, report = normalize_assignments(
                chain_df,
                trajectories=gaze_trajectories,
                junctions=junctions,
                decisions_df=decisions_df,
                prefer_decisions=True,
                include_outliers=False,
            )
            self.logger.info(f&#34;Assignments normalized: in={int(report[&#39;input_rows&#39;])} kept={int(report[&#39;kept_after_tid_map&#39;])} dropped={int(report[&#39;dropped_unmapped_ids&#39;])} decisions={&#39;yes&#39; if report[&#39;has_decisions&#39;] else &#39;no&#39;}&#34;)
            # Extra consistency warnings
            try:
                from .verta_consistency import validate_consistency
                validate_consistency(norm_df, gaze_trajectories, junctions)
            except Exception:
                pass

            gaze_df = compute_head_yaw_at_decisions(
                trajectories=gaze_trajectories,
                junctions=junctions,
                assignments_df=norm_df,
                decision_mode=str(args.decision_mode),
                r_outer_list=rlist,
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                linger_delta=float(args.linger_delta),
            )

        with self.logger.operation(&#34;Computing physiological analysis&#34;):
            physio_df = analyze_physiological_at_junctions(
                trajectories=gaze_trajectories,
                junctions=junctions,
                assignments_df=chain_df,
                decision_mode=str(args.decision_mode),
                r_outer_list=rlist,
                path_length=float(args.distance),
                epsilon=float(args.epsilon),
                linger_delta=float(args.linger_delta),
                physio_window=float(args.physio_window),
            )

        # Save results
        gaze_df.to_csv(os.path.join(args.out, &#34;gaze_analysis.csv&#34;), index=False)
        physio_df.to_csv(os.path.join(args.out, &#34;physiological_analysis.csv&#34;), index=False)

        # Generate consistency report
        consistency = gaze_movement_consistency_report(gaze_df)
        with open(os.path.join(args.out, &#34;gaze_consistency_report.json&#34;), &#34;w&#34;) as f:
            json.dump(consistency, f, indent=2)

        with self.logger.operation(&#34;Generating gaze plots&#34;):
            self._generate_gaze_plots(gaze_trajectories, junctions, gaze_df, physio_df, chain_df, rlist, args)

        self._save_run_args(args, args.out)
        self.logger.info(f&#34;Gaze analysis completed. Results saved to {args.out}&#34;)
        self.logger.info(f&#34;Found {len(gaze_df)} valid gaze-decision pairs&#34;)
        if &#34;mean_absolute_yaw_difference&#34; in consistency:
            self.logger.info(f&#34;Mean head-movement alignment: {consistency[&#39;mean_absolute_yaw_difference&#39;]:.1f}°&#34;)
            self.logger.info(f&#34;Well-aligned decisions: {consistency[&#39;aligned_percentage&#39;]:.1f}%&#34;)

    def _generate_gaze_plots(self, gaze_trajectories, junctions, gaze_df, physio_df, chain_df, rlist, args):
        &#34;&#34;&#34;Generate gaze visualization plots&#34;&#34;&#34;
        try:
            plot_gaze_directions_at_junctions(
                trajectories=gaze_trajectories,
                junctions=junctions,
                gaze_df=gaze_df,
                out_path=os.path.join(args.out, &#34;Gaze_Directions.png&#34;),
                r_outer_list=rlist,
                junction_labels=[f&#34;Junction {i}&#34; for i in range(len(junctions))],
                centers_list=None,  # Optional parameter - not available in this context
            )
            self.logger.info(&#34;Gaze directions plot generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Gaze directions plot failed: {e}&#34;)

        try:
            plot_physiological_by_branch(
                physio_df=physio_df,
                out_path=os.path.join(args.out, &#34;Physiological_Analysis.png&#34;),
            )
            self.logger.info(&#34;Physiological analysis plot generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Physiological analysis plot failed: {e}&#34;)

        # Pupil trajectory analysis
        pupil_traj_df = analyze_pupil_dilation_trajectory(
            trajectories=gaze_trajectories,
            junctions=junctions,
            assignments_df=chain_df,
            decision_mode=str(args.decision_mode),
            r_outer_list=rlist,
            path_length=float(args.distance),
            epsilon=float(args.epsilon),
            linger_delta=float(args.linger_delta),
        )

        pupil_traj_df.to_csv(os.path.join(args.out, &#34;pupil_trajectory_analysis.csv&#34;), index=False)

        try:
            plot_pupil_trajectory_analysis(
                pupil_traj_df=pupil_traj_df,
                out_path=os.path.join(args.out, &#34;Pupil_Trajectory_Analysis.png&#34;),
            )
            self.logger.info(&#34;Pupil trajectory analysis plot generated&#34;)
        except Exception as e:
            self.logger.error(f&#34;Pupil trajectory plot failed: {e}&#34;)</code></pre>
</details>
<div class="desc"><p>Command handler for gaze and physiological analysis</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
<li><code><a title="verta.verta_commands.BaseCommand.execute" href="#verta.verta_commands.BaseCommand.execute">execute</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.IntentRecognitionCommand"><code class="flex name class">
<span>class <span class="ident">IntentRecognitionCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class IntentRecognitionCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for Intent Recognition (ML-based route prediction)&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)

        # Junction specification
        junction_group = parser.add_mutually_exclusive_group(required=True)
        junction_group.add_argument(&#34;--junction&#34;, nargs=3, type=float, metavar=(&#34;X&#34;, &#34;Z&#34;, &#34;R&#34;),
                                   help=&#34;Single junction (x z r)&#34;)
        junction_group.add_argument(&#34;--junctions&#34;, nargs=&#34;+&#34;, type=float,
                                   help=&#34;Multiple junctions (x z r x z r ...)&#34;)

        # Branch discovery/assignment
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--k&#34;, type=int, default=3, help=&#34;Number of clusters&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;hybrid&#34;,
                           help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--cluster_method&#34;, choices=[&#34;kmeans&#34;, &#34;auto&#34;, &#34;dbscan&#34;], default=&#34;kmeans&#34;,
                           help=&#34;Clustering method&#34;)
        parser.add_argument(&#34;--k_min&#34;, type=int, default=2, help=&#34;Minimum k for auto clustering&#34;)
        parser.add_argument(&#34;--k_max&#34;, type=int, default=6, help=&#34;Maximum k for auto clustering&#34;)
        parser.add_argument(&#34;--min_sep_deg&#34;, type=float, default=12.0, help=&#34;Minimum separation in degrees&#34;)
        parser.add_argument(&#34;--angle_eps&#34;, type=float, default=15.0, help=&#34;Angle epsilon for DBSCAN&#34;)
        parser.add_argument(&#34;--min_samples&#34;, type=int, default=5, help=&#34;Minimum samples for DBSCAN&#34;)
        parser.add_argument(&#34;--seed&#34;, type=int, default=0, help=&#34;Random seed&#34;)
        parser.add_argument(&#34;--centers&#34;, help=&#34;Path to pre-computed branch centers (.npy file)&#34;)
        parser.add_argument(&#34;--assignments&#34;, help=&#34;Path to pre-computed branch assignments CSV file&#34;)

        # Intent recognition specific
        parser.add_argument(&#34;--prediction_distances&#34;, nargs=&#34;+&#34;, type=float,
                           default=[100.0, 75.0, 50.0, 25.0],
                           help=&#34;Distances before junction to make predictions (units)&#34;)
        parser.add_argument(&#34;--model_type&#34;, choices=[&#34;random_forest&#34;, &#34;gradient_boosting&#34;],
                           default=&#34;random_forest&#34;, help=&#34;ML model type&#34;)
        parser.add_argument(&#34;--cv_folds&#34;, type=int, default=5, help=&#34;Cross-validation folds&#34;)
        parser.add_argument(&#34;--test_split&#34;, type=float, default=0.2, help=&#34;Test set fraction&#34;)

        # Gaze/physiological data (optional)
        parser.add_argument(&#34;--with_gaze&#34;, action=&#34;store_true&#34;,
                           help=&#34;Load gaze and physiological data if available&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Execute the intent recognition analysis&#34;&#34;&#34;
        logger = get_logger()
        logger.info(&#34;Starting Intent Recognition analysis...&#34;)

        # Check if scikit-learn is available
        try:
            import sklearn
        except ImportError:
            logger.error(&#34;scikit-learn is required for Intent Recognition. Install with: pip install scikit-learn&#34;)
            return

        # Create output directory
        os.makedirs(args.out, exist_ok=True)

        # Load trajectories
        logger.info(f&#34;Loading trajectories from {args.input}&#34;)
        if args.with_gaze:
            trajectories = load_folder_with_gaze(
                folder=args.input,
                pattern=args.glob,
                columns=args.columns,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )
        else:
            trajectories = load_folder(
                folder=args.input,
                pattern=args.glob,
                columns=args.columns,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )

        if not trajectories:
            logger.error(&#34;No trajectories loaded!&#34;)
            return

        logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

        # Parse junctions
        junctions = self._parse_junctions(args)
        logger.info(f&#34;Analyzing {len(junctions)} junction(s)&#34;)

        # Process each junction
        all_results = {}
        summary_data = []

        for junction_idx, junction in enumerate(junctions):
            logger.info(f&#34;\n{&#39;=&#39;*60}&#34;)
            logger.info(f&#34;Processing Junction {junction_idx}&#34;)
            logger.info(f&#34;{&#39;=&#39;*60}&#34;)

            junction_output = os.path.join(args.out, f&#34;junction_{junction_idx}&#34;)
            os.makedirs(junction_output, exist_ok=True)

            # Get branch assignments
            assignments_df = self._get_branch_assignments(
                trajectories, junction, junction_idx, args, junction_output
            )

            if assignments_df is None or assignments_df.empty:
                logger.warning(f&#34;Junction {junction_idx}: No valid branch assignments found. Skipping.&#34;)
                continue

            # Filter valid assignments
            valid_assignments = assignments_df[assignments_df[&#39;branch&#39;] &gt;= 0]
            if len(valid_assignments) &lt; 10:
                logger.warning(f&#34;Junction {junction_idx}: Insufficient valid trajectories ({len(valid_assignments)} &lt; 10). Skipping.&#34;)
                continue

            logger.info(f&#34;Junction {junction_idx}: Found {len(valid_assignments)} valid trajectories&#34;)

            # Run intent recognition
            logger.info(f&#34;Training intent recognition models for Junction {junction_idx}...&#34;)
            results = analyze_intent_recognition(
                trajectories=trajectories,
                junction=junction,
                actual_branches=valid_assignments,
                output_dir=junction_output,
                prediction_distances=args.prediction_distances,
                previous_choices=None  # Could be extended for multi-junction support
            )

            if &#39;error&#39; in results:
                logger.error(f&#34;Junction {junction_idx} failed: {results[&#39;error&#39;]}&#34;)
                all_results[f&#34;junction_{junction_idx}&#34;] = results
                continue

            # Extract summary statistics
            training_results = results.get(&#39;training_results&#39;, {})
            models_trained = training_results.get(&#39;models_trained&#39;, {})

            for dist, model_info in models_trained.items():
                summary_data.append({
                    &#39;junction&#39;: f&#34;J{junction_idx}&#34;,
                    &#39;distance&#39;: dist,
                    &#39;accuracy&#39;: model_info.get(&#39;cv_mean_accuracy&#39;, 0.0) * 100,
                    &#39;std_dev&#39;: model_info.get(&#39;cv_std_accuracy&#39;, 0.0) * 100,
                    &#39;samples&#39;: model_info.get(&#39;n_samples&#39;, 0)
                })

            all_results[f&#34;junction_{junction_idx}&#34;] = results
            logger.info(f&#34;Junction {junction_idx}: Intent recognition complete!&#34;)

        # Save overall summary
        if summary_data:
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_csv(os.path.join(args.out, &#34;intent_recognition_summary.csv&#34;), index=False)

            # Calculate average accuracy per junction
            junction_summary = summary_df.groupby(&#39;junction&#39;).agg({
                &#39;accuracy&#39;: &#39;mean&#39;,
                &#39;samples&#39;: &#39;first&#39;
            }).reset_index()
            junction_summary.columns = [&#39;Junction&#39;, &#39;Avg Accuracy (%)&#39;, &#39;Samples&#39;]
            junction_summary.to_csv(os.path.join(args.out, &#34;intent_recognition_junction_summary.csv&#34;), index=False)

            logger.info(&#34;\n&#34; + &#34;=&#34;*60)
            logger.info(&#34;Intent Recognition Summary&#34;)
            logger.info(&#34;=&#34;*60)
            logger.info(junction_summary.to_string(index=False))

        # Save run arguments
        self._save_run_args(args, args.out)

        # Save full results
        results_path = os.path.join(args.out, &#34;intent_recognition_results.json&#34;)
        # Convert results to JSON-serializable format
        json_results = {}
        for key, value in all_results.items():
            if &#39;analyzer&#39; in value:
                # Remove analyzer object (not JSON serializable)
                json_results[key] = {
                    &#39;training_results&#39;: value.get(&#39;training_results&#39;, {}),
                    &#39;test_predictions&#39;: value.get(&#39;test_predictions&#39;, {})
                }
            else:
                json_results[key] = value

        with open(results_path, &#39;w&#39;) as f:
            json.dump(json_results, f, indent=2, default=str)

        logger.info(f&#34;\nIntent Recognition analysis complete! Results saved to {args.out}&#34;)
        logger.info(f&#34;   - Models saved in: junction_*/models/&#34;)
        logger.info(f&#34;   - Summary: intent_recognition_summary.csv&#34;)
        logger.info(f&#34;   - Full results: intent_recognition_results.json&#34;)

    def _parse_junctions(self, args: argparse.Namespace) -&gt; List[Circle]:
        &#34;&#34;&#34;Parse junction arguments into Circle objects&#34;&#34;&#34;
        if args.junction:
            # Single junction: x z r
            x, z, r = args.junction
            return [Circle(cx=x, cz=z, r=r)]
        elif args.junctions:
            # Multiple junctions: x z r x z r ...
            if len(args.junctions) % 3 != 0:
                raise ValueError(&#34;Junctions must be specified as x z r triplets&#34;)

            junctions = []
            for i in range(0, len(args.junctions), 3):
                x, z, r = args.junctions[i:i+3]
                junctions.append(Circle(cx=x, cz=z, r=r))

            return junctions
        else:
            raise ValueError(&#34;Must specify either --junction or --junctions&#34;)

    def _get_branch_assignments(self, trajectories: List, junction: Circle,
                                junction_idx: int, args: argparse.Namespace,
                                output_dir: str) -&gt; Optional[pd.DataFrame]:
        &#34;&#34;&#34;Get branch assignments either from file or by discovery&#34;&#34;&#34;
        logger = get_logger()

        # Option 1: Load from assignments file
        if args.assignments:
            logger.info(f&#34;Loading branch assignments from {args.assignments}&#34;)
            try:
                assignments_df = pd.read_csv(args.assignments)
                # Check if it has the right columns
                if &#39;trajectory&#39; in assignments_df.columns and &#39;branch&#39; in assignments_df.columns:
                    return assignments_df
                else:
                    logger.warning(&#34;Assignments file missing required columns. Discovering branches instead.&#34;)
            except Exception as e:
                logger.warning(f&#34;Failed to load assignments file: {e}. Discovering branches instead.&#34;)

        # Option 2: Use pre-computed centers
        if args.centers:
            logger.info(f&#34;Using pre-computed branch centers from {args.centers}&#34;)
            try:
                centers = np.load(args.centers)
                assignments_df = assign_branches(
                    trajectories=trajectories,
                    junction=junction,
                    centers=centers,
                    path_length=args.distance,
                    epsilon=args.epsilon,
                    decision_mode=args.decision_mode,
                    linger_delta=args.linger_delta
                )
                # Save assignments for future use
                assignments_df.to_csv(os.path.join(output_dir, &#34;branch_assignments.csv&#34;), index=False)
                return assignments_df
            except Exception as e:
                logger.warning(f&#34;Failed to load centers: {e}. Discovering branches instead.&#34;)

        # Option 3: Discover branches
        logger.info(f&#34;Discovering branches for Junction {junction_idx}...&#34;)
        try:
            centers, assignments_df = discover_branches(
                trajectories=trajectories,
                junction=junction,
                path_length=args.distance,
                epsilon=args.epsilon,
                k=args.k,
                decision_mode=args.decision_mode,
                linger_delta=args.linger_delta,
                cluster_method=args.cluster_method,
                k_min=args.k_min,
                k_max=args.k_max,
                min_sep_deg=args.min_sep_deg,
                angle_eps=args.angle_eps,
                min_samples=args.min_samples,
                seed=args.seed
            )

            # Save discovered centers and assignments
            np.save(os.path.join(output_dir, &#34;branch_centers.npy&#34;), centers)
            assignments_df.to_csv(os.path.join(output_dir, &#34;branch_assignments.csv&#34;), index=False)

            logger.info(f&#34;Discovered {len(centers)} branches with {len(assignments_df[assignments_df[&#39;branch&#39;] &gt;= 0])} valid assignments&#34;)
            return assignments_df

        except Exception as e:
            logger.error(f&#34;Failed to discover branches: {e}&#34;)
            return None</code></pre>
</details>
<div class="desc"><p>Command handler for Intent Recognition (ML-based route prediction)</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="verta.verta_commands.IntentRecognitionCommand.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, args: argparse.Namespace) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, args: argparse.Namespace) -&gt; None:
    &#34;&#34;&#34;Execute the intent recognition analysis&#34;&#34;&#34;
    logger = get_logger()
    logger.info(&#34;Starting Intent Recognition analysis...&#34;)

    # Check if scikit-learn is available
    try:
        import sklearn
    except ImportError:
        logger.error(&#34;scikit-learn is required for Intent Recognition. Install with: pip install scikit-learn&#34;)
        return

    # Create output directory
    os.makedirs(args.out, exist_ok=True)

    # Load trajectories
    logger.info(f&#34;Loading trajectories from {args.input}&#34;)
    if args.with_gaze:
        trajectories = load_folder_with_gaze(
            folder=args.input,
            pattern=args.glob,
            columns=args.columns,
            scale=args.scale,
            motion_threshold=args.motion_threshold
        )
    else:
        trajectories = load_folder(
            folder=args.input,
            pattern=args.glob,
            columns=args.columns,
            scale=args.scale,
            motion_threshold=args.motion_threshold
        )

    if not trajectories:
        logger.error(&#34;No trajectories loaded!&#34;)
        return

    logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

    # Parse junctions
    junctions = self._parse_junctions(args)
    logger.info(f&#34;Analyzing {len(junctions)} junction(s)&#34;)

    # Process each junction
    all_results = {}
    summary_data = []

    for junction_idx, junction in enumerate(junctions):
        logger.info(f&#34;\n{&#39;=&#39;*60}&#34;)
        logger.info(f&#34;Processing Junction {junction_idx}&#34;)
        logger.info(f&#34;{&#39;=&#39;*60}&#34;)

        junction_output = os.path.join(args.out, f&#34;junction_{junction_idx}&#34;)
        os.makedirs(junction_output, exist_ok=True)

        # Get branch assignments
        assignments_df = self._get_branch_assignments(
            trajectories, junction, junction_idx, args, junction_output
        )

        if assignments_df is None or assignments_df.empty:
            logger.warning(f&#34;Junction {junction_idx}: No valid branch assignments found. Skipping.&#34;)
            continue

        # Filter valid assignments
        valid_assignments = assignments_df[assignments_df[&#39;branch&#39;] &gt;= 0]
        if len(valid_assignments) &lt; 10:
            logger.warning(f&#34;Junction {junction_idx}: Insufficient valid trajectories ({len(valid_assignments)} &lt; 10). Skipping.&#34;)
            continue

        logger.info(f&#34;Junction {junction_idx}: Found {len(valid_assignments)} valid trajectories&#34;)

        # Run intent recognition
        logger.info(f&#34;Training intent recognition models for Junction {junction_idx}...&#34;)
        results = analyze_intent_recognition(
            trajectories=trajectories,
            junction=junction,
            actual_branches=valid_assignments,
            output_dir=junction_output,
            prediction_distances=args.prediction_distances,
            previous_choices=None  # Could be extended for multi-junction support
        )

        if &#39;error&#39; in results:
            logger.error(f&#34;Junction {junction_idx} failed: {results[&#39;error&#39;]}&#34;)
            all_results[f&#34;junction_{junction_idx}&#34;] = results
            continue

        # Extract summary statistics
        training_results = results.get(&#39;training_results&#39;, {})
        models_trained = training_results.get(&#39;models_trained&#39;, {})

        for dist, model_info in models_trained.items():
            summary_data.append({
                &#39;junction&#39;: f&#34;J{junction_idx}&#34;,
                &#39;distance&#39;: dist,
                &#39;accuracy&#39;: model_info.get(&#39;cv_mean_accuracy&#39;, 0.0) * 100,
                &#39;std_dev&#39;: model_info.get(&#39;cv_std_accuracy&#39;, 0.0) * 100,
                &#39;samples&#39;: model_info.get(&#39;n_samples&#39;, 0)
            })

        all_results[f&#34;junction_{junction_idx}&#34;] = results
        logger.info(f&#34;Junction {junction_idx}: Intent recognition complete!&#34;)

    # Save overall summary
    if summary_data:
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(os.path.join(args.out, &#34;intent_recognition_summary.csv&#34;), index=False)

        # Calculate average accuracy per junction
        junction_summary = summary_df.groupby(&#39;junction&#39;).agg({
            &#39;accuracy&#39;: &#39;mean&#39;,
            &#39;samples&#39;: &#39;first&#39;
        }).reset_index()
        junction_summary.columns = [&#39;Junction&#39;, &#39;Avg Accuracy (%)&#39;, &#39;Samples&#39;]
        junction_summary.to_csv(os.path.join(args.out, &#34;intent_recognition_junction_summary.csv&#34;), index=False)

        logger.info(&#34;\n&#34; + &#34;=&#34;*60)
        logger.info(&#34;Intent Recognition Summary&#34;)
        logger.info(&#34;=&#34;*60)
        logger.info(junction_summary.to_string(index=False))

    # Save run arguments
    self._save_run_args(args, args.out)

    # Save full results
    results_path = os.path.join(args.out, &#34;intent_recognition_results.json&#34;)
    # Convert results to JSON-serializable format
    json_results = {}
    for key, value in all_results.items():
        if &#39;analyzer&#39; in value:
            # Remove analyzer object (not JSON serializable)
            json_results[key] = {
                &#39;training_results&#39;: value.get(&#39;training_results&#39;, {}),
                &#39;test_predictions&#39;: value.get(&#39;test_predictions&#39;, {})
            }
        else:
            json_results[key] = value

    with open(results_path, &#39;w&#39;) as f:
        json.dump(json_results, f, indent=2, default=str)

    logger.info(f&#34;\nIntent Recognition analysis complete! Results saved to {args.out}&#34;)
    logger.info(f&#34;   - Models saved in: junction_*/models/&#34;)
    logger.info(f&#34;   - Summary: intent_recognition_summary.csv&#34;)
    logger.info(f&#34;   - Full results: intent_recognition_results.json&#34;)</code></pre>
</details>
<div class="desc"><p>Execute the intent recognition analysis</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.MetricsCommand"><code class="flex name class">
<span>class <span class="ident">MetricsCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MetricsCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for timing metrics computation&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)
        parser.add_argument(&#34;--junction&#34;, nargs=2, type=float, required=True, metavar=(&#34;X&#34;, &#34;Z&#34;), help=&#34;Junction coordinates&#34;)
        parser.add_argument(&#34;--radius&#34;, type=float, required=True, help=&#34;Junction radius&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;pathlen&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--r_outer&#34;, type=float, default=None, help=&#34;Outer radius for radial mode&#34;)
        parser.add_argument(&#34;--trend_window&#34;, type=int, default=5, help=&#34;Trend window for radial mode&#34;)
        parser.add_argument(&#34;--min_outward&#34;, type=float, default=0.0, help=&#34;Minimum outward movement&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--regions&#34;, default=None, help=&#34;JSON regions specification&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        self._create_output_dir(args.out)

        with self.logger.operation(&#34;Loading trajectories&#34;):
            trajectories = load_folder(
                args.input, args.glob,
                columns=args.columns,
                require_time=True,
                scale=args.scale,
                motion_threshold=args.motion_threshold
            )

        if len(trajectories) == 0:
            self.logger.error(&#34;No trajectories loaded. Check your input path, file pattern, and column mappings.&#34;)
            return

        junction = Circle(cx=float(args.junction[0]), cz=float(args.junction[1]), r=float(args.radius))

        # Basic consistency check on loaded trajectories
        try:
            validate_trajectories_unique(trajectories)
        except Exception:
            pass

        with self.logger.operation(&#34;Computing timing and speed metrics&#34;):
            rows = []
            for tr in trajectories:
                # Compute timing metrics
                t_val, mode_used = _timing_for_traj(
                    tr=tr,
                    junction=junction,
                    decision_mode=str(args.decision_mode),
                    distance=float(args.distance),
                    r_outer=float(args.r_outer) if args.r_outer is not None else None,
                    trend_window=int(args.trend_window),
                    min_outward=float(args.min_outward),
                )

                # Compute speed metrics
                speed_val, speed_mode = speed_through_junction(
                    tr=tr,
                    junction=junction,
                    decision_mode=str(args.decision_mode),
                    path_length=float(args.distance),
                    r_outer=float(args.r_outer) if args.r_outer is not None else None,
                    window=int(args.trend_window),
                    min_outward=float(args.min_outward),
                )

                # Compute junction transit speeds
                entry_speed, exit_speed, avg_transit_speed = junction_transit_speed(tr, junction)

                row = {
                    &#34;trajectory&#34;: tr.tid,
                    &#34;time_value&#34;: t_val,
                    &#34;decision_mode_requested&#34;: str(args.decision_mode),
                    &#34;decision_mode_used&#34;: mode_used,
                    &#34;distance&#34;: float(args.distance) if mode_used == &#34;pathlen&#34; else None,
                    &#34;r_outer&#34;: float(args.r_outer) if (mode_used == &#34;radial&#34; and args.r_outer is not None) else None,
                    &#34;trend_window&#34;: int(args.trend_window) if mode_used == &#34;radial&#34; else None,
                    &#34;min_outward&#34;: float(args.min_outward) if mode_used == &#34;radial&#34; else None,
                    # Speed analysis columns
                    &#34;speed_through_junction&#34;: speed_val,
                    &#34;speed_mode_used&#34;: speed_mode,
                    &#34;entry_speed&#34;: entry_speed,
                    &#34;exit_speed&#34;: exit_speed,
                    &#34;average_transit_speed&#34;: avg_transit_speed,
                }

                if args.regions:
                    spec = json.loads(args.regions)
                    def parse_region(obj):
                        if &#34;rect&#34; in obj:
                            a,b,c,d = obj[&#34;rect&#34;]
                            from .verta_geometry import Rect
                            return Rect(float(a), float(b), float(c), float(d))
                        if &#34;circle&#34; in obj:
                            a,b,r = obj[&#34;circle&#34;]
                            return Circle(float(a), float(b), float(r))
                    A = parse_region(spec[&#34;A&#34;]) if &#34;A&#34; in spec else None
                    B = parse_region(spec[&#34;B&#34;]) if &#34;B&#34; in spec else None
                    if A is not None and B is not None:
                        tA, tB, dt = time_between_regions(tr, A, B)
                        row.update({&#34;t_A&#34;: tA, &#34;t_B&#34;: tB, &#34;dt_AB&#34;: dt})

                rows.append(row)

            df = pd.DataFrame(rows)
            df.to_csv(os.path.join(args.out, &#34;timing_and_speed_metrics.csv&#34;), index=False)

        self._save_run_args(args, args.out)
        self.logger.info(f&#34;Metrics computation completed. Results saved to {args.out}&#34;)</code></pre>
</details>
<div class="desc"><p>Command handler for timing metrics computation</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
<li><code><a title="verta.verta_commands.BaseCommand.execute" href="#verta.verta_commands.BaseCommand.execute">execute</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="verta.verta_commands.PredictCommand"><code class="flex name class">
<span>class <span class="ident">PredictCommand</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PredictCommand(BaseCommand):
    &#34;&#34;&#34;Command handler for junction-based choice prediction analysis&#34;&#34;&#34;

    def add_arguments(self, parser: argparse.ArgumentParser) -&gt; None:
        parser.add_argument(&#34;--input&#34;, required=True, help=&#34;Input folder path&#34;)
        parser.add_argument(&#34;--out&#34;, required=True, help=&#34;Output folder path&#34;)
        parser.add_argument(&#34;--glob&#34;, default=&#34;*.csv&#34;, help=&#34;File pattern&#34;)
        parser.add_argument(&#34;--columns&#34;, default=None, help=&#34;Column mapping&#34;)
        parser.add_argument(&#34;--scale&#34;, type=float, default=1.0, help=&#34;Coordinate scaling factor&#34;)
        parser.add_argument(&#34;--motion_threshold&#34;, type=float, default=0.001, help=&#34;Motion detection threshold&#34;)
        parser.add_argument(&#34;--junctions&#34;, nargs=&#34;+&#34;, type=float, required=True, help=&#34;Junction coordinates (x z r ...)&#34;)
        parser.add_argument(&#34;--r_outer_list&#34;, nargs=&#34;*&#34;, type=float, default=None, help=&#34;Outer radii for each junction&#34;)
        parser.add_argument(&#34;--distance&#34;, type=float, default=100.0, help=&#34;Path length for decision&#34;)
        parser.add_argument(&#34;--epsilon&#34;, type=float, default=0.015, help=&#34;Minimum step size&#34;)
        parser.add_argument(&#34;--k&#34;, type=int, default=3, help=&#34;Number of clusters&#34;)
        parser.add_argument(&#34;--decision_mode&#34;, choices=[&#34;pathlen&#34;, &#34;radial&#34;, &#34;hybrid&#34;], default=&#34;hybrid&#34;, help=&#34;Decision mode&#34;)
        parser.add_argument(&#34;--linger_delta&#34;, type=float, default=5.0, help=&#34;Linger distance beyond junction&#34;)
        parser.add_argument(&#34;--cluster_method&#34;, choices=[&#34;kmeans&#34;, &#34;auto&#34;, &#34;dbscan&#34;], default=&#34;kmeans&#34;, help=&#34;Clustering method&#34;)
        parser.add_argument(&#34;--k_min&#34;, type=int, default=2, help=&#34;Minimum k for auto clustering&#34;)
        parser.add_argument(&#34;--k_max&#34;, type=int, default=6, help=&#34;Maximum k for auto clustering&#34;)
        parser.add_argument(&#34;--min_sep_deg&#34;, type=float, default=12.0, help=&#34;Minimum separation in degrees&#34;)
        parser.add_argument(&#34;--angle_eps&#34;, type=float, default=15.0, help=&#34;Angle epsilon for DBSCAN&#34;)
        parser.add_argument(&#34;--min_samples&#34;, type=int, default=5, help=&#34;Minimum samples for DBSCAN&#34;)
        parser.add_argument(&#34;--seed&#34;, type=int, default=0, help=&#34;Random seed&#34;)

        # Prediction-specific arguments
        parser.add_argument(&#34;--min_pattern_samples&#34;, type=int, default=3, help=&#34;Minimum samples for pattern recognition&#34;)
        parser.add_argument(&#34;--pattern_threshold&#34;, type=float, default=0.3, help=&#34;Minimum probability threshold for patterns&#34;)
        parser.add_argument(&#34;--confidence_threshold&#34;, type=float, default=0.5, help=&#34;Minimum confidence for predictions&#34;)
        parser.add_argument(&#34;--analyze_sequences&#34;, action=&#34;store_true&#34;, help=&#34;Analyze complete route sequences&#34;)
        parser.add_argument(&#34;--predict_examples&#34;, type=int, default=10, help=&#34;Number of prediction examples to generate&#34;)

    def execute(self, args: argparse.Namespace) -&gt; None:
        &#34;&#34;&#34;Execute the prediction analysis&#34;&#34;&#34;
        logger = get_logger()
        logger.info(&#34;Starting junction-based choice prediction analysis...&#34;)

        # Create output directory
        os.makedirs(args.out, exist_ok=True)

        # Load trajectories
        logger.info(f&#34;Loading trajectories from {args.input}&#34;)
        trajectories = load_folder(
            folder=args.input,
            pattern=args.glob,
            columns=args.columns,
            scale=args.scale,
            motion_threshold=args.motion_threshold
        )

        if not trajectories:
            logger.error(&#34;No trajectories loaded!&#34;)
            return

        logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

        # Parse junctions
        junctions = self._parse_junctions(args.junctions)
        logger.info(f&#34;Analyzing {len(junctions)} junctions&#34;)

        # Discover decision chain
        logger.info(&#34;Discovering decision chains...&#34;)
        chain_df, branch_centers_list = discover_decision_chain(
            trajectories=trajectories,
            junctions=junctions,
            r_outer_list=args.r_outer_list,
            path_length=args.distance,
            epsilon=args.epsilon,
            k=args.k,
            decision_mode=args.decision_mode,
            linger_delta=args.linger_delta,
            cluster_method=args.cluster_method,
            k_min=args.k_min,
            k_max=args.k_max,
            min_sep_deg=args.min_sep_deg,
            angle_eps=args.angle_eps,
            min_samples=args.min_samples,
            seed=args.seed,
            out_dir=args.out
        )

        if chain_df.empty:
            logger.error(&#34;No decision chains discovered!&#34;)
            return

        logger.info(f&#34;Discovered decision chains for {len(chain_df)} trajectories&#34;)

        # Normalize chain for downstream prediction (ID dtype, columns)
        norm_df, _rep = normalize_assignments(
            chain_df,
            trajectories=trajectories,
            junctions=junctions,
            prefer_decisions=False,
            include_outliers=False,
        )
        # Consistency warnings (optional)
        try:
            from verta.verta_consistency import validate_consistency
            validate_consistency(norm_df, trajectories, junctions)
        except Exception:
            pass
        # Save normalized chain
        norm_df.to_csv(os.path.join(args.out, &#34;decision_chains.csv&#34;), index=False)

        # Run prediction analysis
        logger.info(&#34;Analyzing junction choice patterns...&#34;)
        analysis_results = analyze_junction_choice_patterns(
            trajectories=trajectories,
            chain_df=norm_df,
            junctions=junctions,
            output_dir=args.out,
            r_outer_list=args.r_outer_list,
            gui_mode=False  # Terminal mode
        )

        # Generate additional analysis if requested
        if args.analyze_sequences:
            self._analyze_route_sequences(norm_df, junctions, args.out)

        # Generate prediction examples
        if args.predict_examples &gt; 0:
            self._generate_prediction_examples(trajectories, norm_df, junctions, args.out, args.predict_examples)

        # Save summary
        self._save_analysis_summary(analysis_results, args.out)

        logger.info(f&#34;Prediction analysis complete! Results saved to {args.out}&#34;)

    def _parse_junctions(self, junction_args: List[float]) -&gt; List[Circle]:
        &#34;&#34;&#34;Parse junction arguments into Circle objects&#34;&#34;&#34;
        if len(junction_args) % 3 != 0:
            raise ValueError(&#34;Junctions must be specified as x z r triplets&#34;)

        junctions = []
        for i in range(0, len(junction_args), 3):
            x, z, r = junction_args[i:i+3]
            junctions.append(Circle(cx=x, cz=z, r=r))

        return junctions

    def _analyze_route_sequences(self, chain_df: pd.DataFrame, junctions: List[Circle], output_dir: str):
        &#34;&#34;&#34;Analyze complete route sequences for behavioral patterns&#34;&#34;&#34;
        logger = get_logger()
        logger.info(&#34;Analyzing route sequences...&#34;)

        # Extract sequences
        sequences = []
        for _, row in chain_df.iterrows():
            sequence = []
            for i in range(len(junctions)):
                branch_col = f&#34;branch_j{i}&#34;
                if branch_col in row and pd.notna(row[branch_col]):
                    sequence.append(int(row[branch_col]))
                else:
                    break

            if len(sequence) &gt; 1:
                sequences.append(sequence)

        # Analyze sequence patterns
        sequence_analysis = {
            &#39;total_sequences&#39;: len(sequences),
            &#39;sequence_lengths&#39;: [len(seq) for seq in sequences],
            &#39;common_patterns&#39;: self._find_common_sequence_patterns(sequences),
            &#39;sequence_diversity&#39;: len(set(tuple(seq) for seq in sequences)),
            &#39;average_length&#39;: np.mean([len(seq) for seq in sequences]) if sequences else 0
        }

        # Save sequence analysis
        with open(os.path.join(output_dir, &#34;sequence_analysis.json&#34;), &#34;w&#34;) as f:
            json.dump(sequence_analysis, f, indent=2)

        logger.info(f&#34;Found {len(sequences)} route sequences&#34;)

    def _find_common_sequence_patterns(self, sequences: List[List[int]]) -&gt; List[Dict[str, Any]]:
        &#34;&#34;&#34;Find common patterns in route sequences&#34;&#34;&#34;
        # Count sequence patterns
        sequence_counts = Counter(tuple(seq) for seq in sequences)

        # Get most common patterns
        common_patterns = []
        for pattern, count in sequence_counts.most_common(10):
            if count &gt; 1:  # Only patterns that occur more than once
                common_patterns.append({
                    &#39;pattern&#39;: list(pattern),
                    &#39;count&#39;: count,
                    &#39;frequency&#39;: count / len(sequences)
                })

        return common_patterns

    def _generate_prediction_examples(self, trajectories: List[Trajectory], chain_df: pd.DataFrame, junctions: List[Circle],
                                    output_dir: str, num_examples: int):
        &#34;&#34;&#34;Generate prediction examples for sample trajectories&#34;&#34;&#34;
        logger = get_logger()
        logger.info(f&#34;Generating {num_examples} prediction examples...&#34;)

        # Initialize analyzer
        analyzer = JunctionChoiceAnalyzer(trajectories, chain_df, junctions)

        # Get sample trajectories
        sample_trajectories = chain_df.head(num_examples)

        predictions = []
        for _, row in sample_trajectories.iterrows():
            trajectory_id = row[&#39;trajectory&#39;]

            # Find first junction with a valid branch
            for i in range(len(junctions)):
                branch_col = f&#34;branch_j{i}&#34;
                if branch_col in row and pd.notna(row[branch_col]):
                    current_junction = i
                    current_branch = int(row[branch_col])

                    # Make prediction
                    prediction = analyzer.predict_next_choice(trajectory_id, current_junction, current_branch)
                    predictions.append(prediction)
                    break

        # Save prediction examples
        prediction_data = []
        for pred in predictions:
            prediction_data.append({
                &#39;trajectory_id&#39;: pred.trajectory_id,
                &#39;current_junction&#39;: pred.current_junction,
                &#39;current_branch&#39;: pred.current_branch,
                &#39;predicted_next_junction&#39;: pred.predicted_next_junction,
                &#39;predicted_next_branch&#39;: pred.predicted_next_branch,
                &#39;confidence&#39;: pred.confidence,
                &#39;pattern_used&#39;: pred.pattern_used,
                &#39;alternatives&#39;: [
                    {&#39;junction&#39;: j, &#39;branch&#39;: b, &#39;probability&#39;: p}
                    for j, b, p in pred.alternative_predictions
                ]
            })

        with open(os.path.join(output_dir, &#34;prediction_examples.json&#34;), &#34;w&#34;) as f:
            json.dump(prediction_data, f, indent=2)

        logger.info(f&#34;Generated {len(predictions)} prediction examples&#34;)

    def _save_analysis_summary(self, analysis_results: Dict[str, Any], output_dir: str):
        &#34;&#34;&#34;Save a summary of the analysis results&#34;&#34;&#34;
        summary = {
            &#39;analysis_type&#39;: &#39;Junction-Based Choice Prediction&#39;,
            &#39;summary&#39;: analysis_results[&#39;summary&#39;],
            &#39;key_findings&#39;: {
                &#39;total_patterns&#39;: analysis_results[&#39;summary&#39;][&#39;unique_patterns&#39;],
                &#39;pattern_distribution&#39;: analysis_results[&#39;pattern_types&#39;],
                &#39;top_pattern&#39;: analysis_results[&#39;top_patterns&#39;][0] if analysis_results[&#39;top_patterns&#39;] else None
            },
            &#39;recommendations&#39;: self._generate_recommendations(analysis_results)
        }

        with open(os.path.join(output_dir, &#34;analysis_summary.json&#34;), &#34;w&#34;) as f:
            json.dump(summary, f, indent=2)

    def _generate_recommendations(self, analysis_results: Dict[str, Any]) -&gt; List[str]:
        &#34;&#34;&#34;Generate recommendations based on analysis results&#34;&#34;&#34;
        recommendations = []

        # Check for strong patterns
        preferred_patterns = [p for p in analysis_results[&#39;top_patterns&#39;] if p[&#39;pattern_type&#39;] == &#39;preferred&#39;]
        if preferred_patterns:
            recommendations.append(f&#34;Found {len(preferred_patterns)} strong behavioral patterns that could be used for route prediction&#34;)

        # Check for junction-specific insights
        junction_analysis = analysis_results[&#39;junction_analysis&#39;]
        for junction_idx, analysis in junction_analysis.items():
            if analysis[&#39;pattern_diversity&#39;] == 1:
                recommendations.append(f&#34;Junction {junction_idx} shows very predictable behavior - consider this for traffic optimization&#34;)
            elif analysis[&#39;pattern_diversity&#39;] &gt; 3:
                recommendations.append(f&#34;Junction {junction_idx} shows high variability - may need better signage or design&#34;)

        # Check for learning opportunities
        learned_patterns = [p for p in analysis_results[&#39;top_patterns&#39;] if p[&#39;pattern_type&#39;] == &#39;learned&#39;]
        if learned_patterns:
            recommendations.append(f&#34;Found {len(learned_patterns)} learned patterns - participants are adapting to the environment&#34;)

        return recommendations</code></pre>
</details>
<div class="desc"><p>Command handler for junction-based choice prediction analysis</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="verta.verta_commands.PredictCommand.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, args: argparse.Namespace) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, args: argparse.Namespace) -&gt; None:
    &#34;&#34;&#34;Execute the prediction analysis&#34;&#34;&#34;
    logger = get_logger()
    logger.info(&#34;Starting junction-based choice prediction analysis...&#34;)

    # Create output directory
    os.makedirs(args.out, exist_ok=True)

    # Load trajectories
    logger.info(f&#34;Loading trajectories from {args.input}&#34;)
    trajectories = load_folder(
        folder=args.input,
        pattern=args.glob,
        columns=args.columns,
        scale=args.scale,
        motion_threshold=args.motion_threshold
    )

    if not trajectories:
        logger.error(&#34;No trajectories loaded!&#34;)
        return

    logger.info(f&#34;Loaded {len(trajectories)} trajectories&#34;)

    # Parse junctions
    junctions = self._parse_junctions(args.junctions)
    logger.info(f&#34;Analyzing {len(junctions)} junctions&#34;)

    # Discover decision chain
    logger.info(&#34;Discovering decision chains...&#34;)
    chain_df, branch_centers_list = discover_decision_chain(
        trajectories=trajectories,
        junctions=junctions,
        r_outer_list=args.r_outer_list,
        path_length=args.distance,
        epsilon=args.epsilon,
        k=args.k,
        decision_mode=args.decision_mode,
        linger_delta=args.linger_delta,
        cluster_method=args.cluster_method,
        k_min=args.k_min,
        k_max=args.k_max,
        min_sep_deg=args.min_sep_deg,
        angle_eps=args.angle_eps,
        min_samples=args.min_samples,
        seed=args.seed,
        out_dir=args.out
    )

    if chain_df.empty:
        logger.error(&#34;No decision chains discovered!&#34;)
        return

    logger.info(f&#34;Discovered decision chains for {len(chain_df)} trajectories&#34;)

    # Normalize chain for downstream prediction (ID dtype, columns)
    norm_df, _rep = normalize_assignments(
        chain_df,
        trajectories=trajectories,
        junctions=junctions,
        prefer_decisions=False,
        include_outliers=False,
    )
    # Consistency warnings (optional)
    try:
        from verta.verta_consistency import validate_consistency
        validate_consistency(norm_df, trajectories, junctions)
    except Exception:
        pass
    # Save normalized chain
    norm_df.to_csv(os.path.join(args.out, &#34;decision_chains.csv&#34;), index=False)

    # Run prediction analysis
    logger.info(&#34;Analyzing junction choice patterns...&#34;)
    analysis_results = analyze_junction_choice_patterns(
        trajectories=trajectories,
        chain_df=norm_df,
        junctions=junctions,
        output_dir=args.out,
        r_outer_list=args.r_outer_list,
        gui_mode=False  # Terminal mode
    )

    # Generate additional analysis if requested
    if args.analyze_sequences:
        self._analyze_route_sequences(norm_df, junctions, args.out)

    # Generate prediction examples
    if args.predict_examples &gt; 0:
        self._generate_prediction_examples(trajectories, norm_df, junctions, args.out, args.predict_examples)

    # Save summary
    self._save_analysis_summary(analysis_results, args.out)

    logger.info(f&#34;Prediction analysis complete! Results saved to {args.out}&#34;)</code></pre>
</details>
<div class="desc"><p>Execute the prediction analysis</p></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></b></code>:
<ul class="hlist">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="verta" href="index.html">verta</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="verta.verta_commands.AssignCommand" href="#verta.verta_commands.AssignCommand">AssignCommand</a></code></h4>
</li>
<li>
<h4><code><a title="verta.verta_commands.BaseCommand" href="#verta.verta_commands.BaseCommand">BaseCommand</a></code></h4>
<ul class="">
<li><code><a title="verta.verta_commands.BaseCommand.add_arguments" href="#verta.verta_commands.BaseCommand.add_arguments">add_arguments</a></code></li>
<li><code><a title="verta.verta_commands.BaseCommand.execute" href="#verta.verta_commands.BaseCommand.execute">execute</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="verta.verta_commands.CommandConfig" href="#verta.verta_commands.CommandConfig">CommandConfig</a></code></h4>
<ul class="two-column">
<li><code><a title="verta.verta_commands.CommandConfig.columns" href="#verta.verta_commands.CommandConfig.columns">columns</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.config" href="#verta.verta_commands.CommandConfig.config">config</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.glob" href="#verta.verta_commands.CommandConfig.glob">glob</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.input" href="#verta.verta_commands.CommandConfig.input">input</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.motion_threshold" href="#verta.verta_commands.CommandConfig.motion_threshold">motion_threshold</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.out" href="#verta.verta_commands.CommandConfig.out">out</a></code></li>
<li><code><a title="verta.verta_commands.CommandConfig.scale" href="#verta.verta_commands.CommandConfig.scale">scale</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="verta.verta_commands.DiscoverCommand" href="#verta.verta_commands.DiscoverCommand">DiscoverCommand</a></code></h4>
</li>
<li>
<h4><code><a title="verta.verta_commands.EnhancedChainCommand" href="#verta.verta_commands.EnhancedChainCommand">EnhancedChainCommand</a></code></h4>
<ul class="">
<li><code><a title="verta.verta_commands.EnhancedChainCommand.execute" href="#verta.verta_commands.EnhancedChainCommand.execute">execute</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="verta.verta_commands.GUICommand" href="#verta.verta_commands.GUICommand">GUICommand</a></code></h4>
<ul class="">
<li><code><a title="verta.verta_commands.GUICommand.execute" href="#verta.verta_commands.GUICommand.execute">execute</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="verta.verta_commands.GazeCommand" href="#verta.verta_commands.GazeCommand">GazeCommand</a></code></h4>
</li>
<li>
<h4><code><a title="verta.verta_commands.IntentRecognitionCommand" href="#verta.verta_commands.IntentRecognitionCommand">IntentRecognitionCommand</a></code></h4>
<ul class="">
<li><code><a title="verta.verta_commands.IntentRecognitionCommand.execute" href="#verta.verta_commands.IntentRecognitionCommand.execute">execute</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="verta.verta_commands.MetricsCommand" href="#verta.verta_commands.MetricsCommand">MetricsCommand</a></code></h4>
</li>
<li>
<h4><code><a title="verta.verta_commands.PredictCommand" href="#verta.verta_commands.PredictCommand">PredictCommand</a></code></h4>
<ul class="">
<li><code><a title="verta.verta_commands.PredictCommand.execute" href="#verta.verta_commands.PredictCommand.execute">execute</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
